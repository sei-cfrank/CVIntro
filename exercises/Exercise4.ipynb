{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Pretrained Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'picamera2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Important that this code block is only run once!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Otherwise will need to restart kernel\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpicamera2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Picamera2\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimeit\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'picamera2'"
     ]
    }
   ],
   "source": [
    "# Important that this code block is only run once!\n",
    "# Otherwise will need to restart kernel\n",
    "from picamera2 import Picamera2\n",
    "import timeit\n",
    "import cv2\n",
    "\n",
    "# instantiate camera instance\n",
    "picam2 = Picamera2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0:13:05.947717925] [3210] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1183 \u001b[0mconfiguring streams: (0) 1536x864-XRGB8888 (1) 1536x864-BGGR16_PISP_COMP1\n",
      "[0:13:05.953013906] [3135] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1405 \u001b[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/imx708@1a - Selected sensor format: 1536x864-SBGGR10_1X10 - Selected CFE format: 1536x864-PC1B\n"
     ]
    }
   ],
   "source": [
    "# create a config with desired attributes: format, size, framerate\n",
    "# NOTE: camera resolution 4608x2464, downsamples at 2304x1296 (56.03 fps)\n",
    "# NOTE: XRGB8888 => shape: (height, width, 4); pixel value: [B, G, R, A]\n",
    "config = picam2.create_preview_configuration(\n",
    "    main={'format': 'XRGB8888', 'size': (2304, 1296)})  # 16:9 aspect ratio\n",
    "\n",
    "# set camera configuration, start camera\n",
    "picam2.configure(config)\n",
    "picam2.start()\n",
    "\n",
    "# start opencv window thread\n",
    "cv2.startWindowThread()\n",
    "wnd_name = 'foo'\n",
    "cv2.namedWindow(wnd_name, cv2.WINDOW_KEEPRATIO)\n",
    "cv2.resizeWindow(wnd_name, 640, 480)                    # 4:3 aspect ratio\n",
    "\n",
    "while True:\n",
    "    # get current image data from 'main' camera stream\n",
    "    arr1 = picam2.capture_array('main')\n",
    "\n",
    "    # resize the image data using bi-linear interpolation\n",
    "    arr2 = cv2.resize(arr1, (640, 480), 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "    # if window closed, break loop before imshow creates new window\n",
    "    if cv2.getWindowProperty(wnd_name, cv2.WND_PROP_AUTOSIZE) == -1:\n",
    "        break\n",
    "\n",
    "    # show resized image\n",
    "    cv2.imshow(wnd_name, arr2)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# stop camera\n",
    "cv2.destroyWindow(wnd_name)\n",
    "picam2.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tExercise 3: Transforming images for inference using software.  \n",
    "    a.\tlibcamera document:  \n",
    "    b.\tOpenCV package (maybe Numpy package too)  \n",
    "    c.\tNative resolution: 3280x2264, half this  \n",
    "    d.\ttiling, resizing, scaling, letterboxing (lecture 3 need to cover these topics)  \n",
    "    e.\tChanging packing scheme  \n",
    "    f.\tGoal: 3x416x416 (in RGB order, no alpha)  \n",
    "    g.\tProvide code for three different options  \n",
    "    h.\tProvide preprocessing code provided from ONNX model zoo page.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letterbox procedure\n",
    "def letterbox(src, dest_shape):\n",
    "    # get src dims\n",
    "    src_width = src.shape[1]    # img.shape returns tuple (rows, cols, chan)\n",
    "    src_height = src.shape[0]   # NOTE: rows => height; cols => width\n",
    "\n",
    "    # cons dest array (filled with gray), get dest dims\n",
    "    # NOTE: each 32-bit [B, G, R, A] pixel value is [128, 128, 128, 255]\n",
    "    dest = np.full(dest_shape, np.uint8(128))\n",
    "    dest[:, :, 3] = np.uint8(255)\n",
    "    dest_width = dest.shape[1]\n",
    "    dest_height = dest.shape[0]\n",
    "\n",
    "    # calculate width and height ratios\n",
    "    width_ratio = dest_width / src_width        # NOTE: ratios are float values\n",
    "    height_ratio = dest_height / src_height\n",
    "\n",
    "    # init resized image width and height with max values (dest dims)\n",
    "    rsz_width = dest_width\n",
    "    rsz_height = dest_height\n",
    "\n",
    "    # smallest scale factor will scale other dimension as well\n",
    "    if width_ratio < height_ratio:\n",
    "        rsz_height = int(src_height * width_ratio)  # NOTE: integer truncation\n",
    "    else:\n",
    "        rsz_width = int(src_width * height_ratio)\n",
    "\n",
    "    # resize the image data using bi-linear interpolation\n",
    "    rsz_dims = (rsz_width, rsz_height)\n",
    "    rsz = cv2.resize(src, rsz_dims, 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "    # embed rsz into the center of dest\n",
    "    dx = int((dest_width - rsz_width) / 2)          # NOTE: integer truncation\n",
    "    dy = int((dest_height - rsz_height) / 2)\n",
    "    dest[dy:dy+rsz_height, dx:dx+rsz_width, :] = rsz\n",
    "\n",
    "    # letterboxing complete, return dest\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack_buffer procedure, ONNX model expects normalized float32 NCHW tensor\n",
    "def pack_buffer(src):\n",
    "    dest = np.array(src, dtype='float32')       # cons dest array via copy\n",
    "    dest = dest[:, :, :3]                       # remove alpha channel\n",
    "    dest = dest[..., ::-1]                      # reorder channels: BGR -> RGB\n",
    "    dest /= 255.0                               # normalize vals\n",
    "    dest = np.transpose(dest, [2, 0, 1])        # make channel first dim\n",
    "    dest = np.expand_dims(dest, 0)              # ins batch dim before chan dim\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config with desired attributes: format, size, framerate\n",
    "# NOTE: camera resolution 4608x2464, downsamples at 2304x1296 (56.03 fps)\n",
    "# NOTE: XRGB8888 => shape: (height, width, 4); pixel value: [B, G, R, A]\n",
    "config = picam2.create_preview_configuration(\n",
    "    main={'format': 'XRGB8888', 'size': (2304, 1296)})  # 16:9 aspect ratio\n",
    "\n",
    "# set camera configuration, start camera\n",
    "picam2.configure(config)\n",
    "picam2.start()\n",
    "\n",
    "# start opencv window thread\n",
    "cv2.startWindowThread()\n",
    "wnd_name = 'foo'\n",
    "cv2.namedWindow(wnd_name, cv2.WINDOW_KEEPRATIO)\n",
    "cv2.resizeWindow(wnd_name, 416, 416)                    # 1:1 aspect ratio\n",
    "\n",
    "while True:\n",
    "    # get current image data from 'main' camera stream\n",
    "    arr1 = picam2.capture_array('main')\n",
    "\n",
    "    # letterbox the image to resize for NN input (size: (height, width, chan))\n",
    "    arr2 = letterbox(arr1, (416, 416, 4))\n",
    "\n",
    "    # cons packed input buffer for ONNX model inference\n",
    "    arr3 = pack_buffer(arr2)\n",
    "    dim3 = np.array([arr2.shape[1],arr2.shape[0]],dtype=np.float32).reshape(1,2)\n",
    "\n",
    "    # run ONNX model inference on input buffer to get results\n",
    "    # res = infer(arr3, dim3)\n",
    "\n",
    "    # process results to make list of annotations\n",
    "    # annos = proc_results(res)\n",
    "\n",
    "    # draw list of annotations on letterboxed image\n",
    "    # arr4 = draw_annos(annos, arr2)\n",
    "\n",
    "    # if window closed, break loop before imshow creates new window\n",
    "    if cv2.getWindowProperty(wnd_name, cv2.WND_PROP_AUTOSIZE) == -1:\n",
    "        break\n",
    "\n",
    "    # show annotated image\n",
    "    # cv2.imshow(wnd_name, arr4)\n",
    "    cv2.imshow(wnd_name, arr2)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# stop camera\n",
    "cv2.destroyWindow(wnd_name)\n",
    "picam2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pre-Trained Neural Networks (PTNNs)\n",
    "    a.\tPTNNs have architecture and trained weights.  \n",
    "    b.\tGetting trained Tiny YOLOv3 from ONNX model zoo  \n",
    "    c.\tConsider NETRON model viewer (https://github.com/lutzroeder/netron)  \n",
    "    d.\tonnx2torch module  \n",
    "    e.\tLoading ONNX model into pytorch  \n",
    "    f.\tRun on a test image look at output: bbox center and extent, objectness, classifications.  \n",
    "    g.\tNOTE: use a very busy test image -> lots of bounding boxes  \n",
    "    h.\t[raw Yolo output is just numbers, not an image, what does it mean? Cue lecture 5  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letterbox procedure\n",
    "def letterbox(src, dest_shape):\n",
    "    # get src dims\n",
    "    src_width = src.shape[1]    # img.shape returns tuple (rows, cols, chan)\n",
    "    src_height = src.shape[0]   # NOTE: rows => height; cols => width\n",
    "\n",
    "    # cons dest array (filled with gray), get dest dims\n",
    "    # NOTE: each 32-bit [B, G, R, A] pixel value is [128, 128, 128, 255]\n",
    "    dest = np.full(dest_shape, np.uint8(128))\n",
    "    dest[:, :, 3] = np.uint8(255)\n",
    "    dest_width = dest.shape[1]\n",
    "    dest_height = dest.shape[0]\n",
    "\n",
    "    # calculate width and height ratios\n",
    "    width_ratio = dest_width / src_width        # NOTE: ratios are float values\n",
    "    height_ratio = dest_height / src_height\n",
    "\n",
    "    # init resized image width and height with max values (dest dims)\n",
    "    rsz_width = dest_width\n",
    "    rsz_height = dest_height\n",
    "\n",
    "    # smallest scale factor will scale other dimension as well\n",
    "    if width_ratio < height_ratio:\n",
    "        rsz_height = int(src_height * width_ratio)  # NOTE: integer truncation\n",
    "    else:\n",
    "        rsz_width = int(src_width * height_ratio)\n",
    "\n",
    "    # resize the image data using bi-linear interpolation\n",
    "    rsz_dims = (rsz_width, rsz_height)\n",
    "    rsz = cv2.resize(src, rsz_dims, 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "    # embed rsz into the center of dest\n",
    "    dx = int((dest_width - rsz_width) / 2)          # NOTE: integer truncation\n",
    "    dy = int((dest_height - rsz_height) / 2)\n",
    "    dest[dy:dy+rsz_height, dx:dx+rsz_width, :] = rsz\n",
    "\n",
    "    # letterboxing complete, return dest\n",
    "    return dest\n",
    "\n",
    "# pack_buffer procedure, ONNX model expects normalized float32 NCHW tensor\n",
    "def pack_buffer(src):\n",
    "    dest = np.array(src, dtype='float32')       # cons dest array via copy\n",
    "    dest = dest[:, :, :3]                       # remove alpha channel\n",
    "    dest = dest[..., ::-1]                      # reorder channels: BGR -> RGB\n",
    "    dest /= 255.0                               # normalize vals\n",
    "    dest = np.transpose(dest, [2, 0, 1])        # make channel first dim\n",
    "    dest = np.expand_dims(dest, 0)              # ins batch dim before chan dim\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cons ONNX Tiny YOLOv3 NN model\n",
    "onnx_model_path = '../model/yolov3-tiny.onnx'\n",
    "infer_sess = ort.InferenceSession(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# instantiate camera instance\n",
    "#picam2 = Picamera2()\n",
    "\n",
    "# create a config with desired attributes: format, size, framerate\n",
    "# NOTE: camera resolution 4608x2464, downsamples at 2304x1296 (56.03 fps)\n",
    "# NOTE: XRGB8888 => shape: (height, width, 4); pixel value: [B, G, R, A]\n",
    "config = picam2.create_preview_configuration(\n",
    "    main={'format': 'XRGB8888', 'size': (2304, 1296)})  # 16:9 aspect ratio\n",
    "\n",
    "# set camera configuration, start camera\n",
    "picam2.configure(config)\n",
    "picam2.start()\n",
    "\n",
    "# start opencv window thread\n",
    "cv2.startWindowThread()\n",
    "wnd_name = 'foo'\n",
    "cv2.namedWindow(wnd_name, cv2.WINDOW_KEEPRATIO)\n",
    "cv2.resizeWindow(wnd_name, 416, 416)                    # 1:1 aspect ratio\n",
    "\n",
    "while True:\n",
    "    # get current image data from 'main' camera stream\n",
    "    arr1 = picam2.capture_array('main')\n",
    "\n",
    "    # letterbox the image to resize for NN input (size: (height, width, chan))\n",
    "    arr2 = letterbox(arr1, (416, 416, 4))\n",
    "\n",
    "    # cons packed input buffer for  model inference\n",
    "    arr3 = pack_buffer(arr2)\n",
    "    dim3 = np.array([arr2.shape[1],arr2.shape[0]],dtype=np.float32).reshape(1,2)\n",
    "\n",
    "    # run ONNX model inference on input buffer to get results\n",
    "    res = infer_sess.run(None, {'input_1': arr3, 'image_shape': dim3})\n",
    "\n",
    "    # process results to make list of annotations\n",
    "    # annos = proc_results(res)\n",
    "\n",
    "    # draw list of annotations on letterboxed image\n",
    "    # arr4 = draw_annos(annos, arr2)\n",
    "\n",
    "    # if window closed, break loop before imshow creates new window\n",
    "    if cv2.getWindowProperty(wnd_name, cv2.WND_PROP_AUTOSIZE) == -1:\n",
    "        break\n",
    "\n",
    "    # show annotated image\n",
    "    # cv2.imshow(wnd_name, arr4)\n",
    "    cv2.imshow(wnd_name, arr2)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# stop camera\n",
    "cv2.destroyWindow(wnd_name)\n",
    "picam2.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
