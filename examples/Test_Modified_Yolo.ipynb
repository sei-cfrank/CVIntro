{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cd24b-ecb8-4d8f-9d22-1060cf6dda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26754016-eded-44ca-a9ff-a656afe02aae",
   "metadata": {},
   "source": [
    "* Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b61a8-3a72-48af-91c1-54e66ac26f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letterbox procedure\n",
    "def letterbox(src, dest_shape):\n",
    "    # get src dims\n",
    "    src_width = src.shape[1]    # img.shape returns tuple (rows, cols, chan)\n",
    "    src_height = src.shape[0]   # NOTE: rows => height; cols => width\n",
    "\n",
    "    # cons dest array (filled with gray), get dest dims\n",
    "    # NOTE: each 32-bit [R, G, B] pixel value is [128, 128, 128]\n",
    "    dest = np.full(dest_shape, np.uint8(128))\n",
    "    dest_width = dest.shape[1]\n",
    "    dest_height = dest.shape[0]\n",
    "\n",
    "    # calculate width and height ratios\n",
    "    width_ratio = dest_width / src_width        # NOTE: ratios are float values\n",
    "    height_ratio = dest_height / src_height\n",
    "\n",
    "    # init resized image width and height with max values (dest dims)\n",
    "    rsz_width = dest_width\n",
    "    rsz_height = dest_height\n",
    "\n",
    "    # smallest scale factor will scale other dimension as well\n",
    "    if width_ratio < height_ratio:\n",
    "        rsz_height = int(src_height * width_ratio)  # NOTE: integer truncation\n",
    "    else:\n",
    "        rsz_width = int(src_width * height_ratio)\n",
    "\n",
    "    # resize the image data using bi-linear interpolation\n",
    "    rsz_dims = (rsz_width, rsz_height)\n",
    "    rsz = cv2.resize(src, rsz_dims, 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "    # embed rsz into the center of dest\n",
    "    dx = int((dest_width - rsz_width) / 2)          # NOTE: integer truncation\n",
    "    dy = int((dest_height - rsz_height) / 2)\n",
    "    dest[dy:dy+rsz_height, dx:dx+rsz_width, :] = rsz\n",
    "\n",
    "    # letterboxing complete, return dest\n",
    "    return dest\n",
    "\n",
    "# pack_buffer procedure, ONNX model expects normalized float32 NCHW tensor\n",
    "def pack_buffer(src):\n",
    "    dest = np.array(src, dtype='float32')       # cons dest array via copy\n",
    "    dest /= 255.0                               # normalize vals\n",
    "    dest = np.transpose(dest, [2, 0, 1])        # make channel first dim\n",
    "    dest = np.expand_dims(dest, 0)              # ins batch dim before chan dim\n",
    "    return dest\n",
    "\n",
    "# proc_results procedure\n",
    "def proc_results(res):\n",
    "    [boxes, scores, indices] = res\n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    for idx in indices[0]:\n",
    "        out_classes.append(idx[1])\n",
    "        out_scores.append(scores[tuple(idx)])\n",
    "        idx1 = (idx[0], idx[2])\n",
    "        out_boxes.append(boxes[idx1])\n",
    "    return list(zip(out_boxes, out_scores, out_classes))\n",
    "\n",
    "# draw_annos procedure\n",
    "def draw_annos(src, annos, coco_names):\n",
    "    dest = np.copy(src)\n",
    "    #print(f'>>> annos\\n{annos}')\n",
    "    green = (0, 255, 0)\n",
    "    black = (0, 0, 0)\n",
    "    face = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    scale = 0.5\n",
    "    thickness = 1\n",
    "    for anno in annos:\n",
    "        pt1 = (int(anno[0][0]), int(anno[0][1]))\n",
    "        pt2 = (int(anno[0][2]), int(anno[0][3]))\n",
    "        text = f'{coco_names[anno[2]]}: {anno[1]:6.4f}'\n",
    "        (w, h), _ = cv2.getTextSize(text, face, scale, thickness)\n",
    "        pt3 = (pt1[0], int(pt1[1] - h))\n",
    "        pt4 = (int(pt1[0] + w), pt1[1])\n",
    "        dest = cv2.rectangle(src, pt1, pt2, green)\n",
    "        dest = cv2.rectangle(dest, pt3, pt4, green, cv2.FILLED)\n",
    "        dest = cv2.putText(dest, text, pt1, face, scale, black, thickness)\n",
    "    return dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097fb33-11ce-402b-836a-023d8442edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display test image\n",
    "\n",
    "# open test image\n",
    "arr1 = cv2.imread('../data/dog.jpg')  # default: bgr for display\n",
    "plt.imshow(arr1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2e529-c8c6-4f68-8b32-87c441499b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use openCV to reverse channel order\n",
    "plt.imshow(cv2.cvtColor(arr1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072d360-0295-4149-a1a7-51aa50570dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert channels a different way\n",
    "\n",
    "arr2 = arr1[..., ::-1]                  # bgr -> rgb for inference\n",
    "plt.imshow(arr2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be45f29-7efa-44cc-9cb2-0b815dcbddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letterbox the image to resize for NN input (size: (height, width, chan))\n",
    "letterbox_img = letterbox(arr2, (416, 416, 3))\n",
    "plt.imshow(letterbox_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae440c8-4c31-456d-bac7-9619dbd31297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the model classes\n",
    "def read_model_classes(pathname = '../model/coco.names'):\n",
    "    file = open(pathname, 'r')\n",
    "    classes = []\n",
    "    while True:\n",
    "        class_name = file.readline().strip()\n",
    "        if not class_name:\n",
    "            break\n",
    "        classes.append(class_name)\n",
    "    file.close()\n",
    "    return classes\n",
    "\n",
    "def run_inference(model, image_array):\n",
    "    # cons input for ONNX model inference (packed images and their orig dims)\n",
    "    img = pack_buffer(image_array)\n",
    "    #dim4 = np.array([image_array.shape[1], image_array.shape[0]], dtype=np.float32).reshape(1, 2)\n",
    "\n",
    "    # run ONNX model inference on input buffer to get results\n",
    "    return model.run(None, {'input_1': img}) #, 'image_shape': dim4})\n",
    "\n",
    "classes = read_model_classes()\n",
    "#print(\"Classes:\",classes)\n",
    "\n",
    "model   = ort.InferenceSession('../model/modified_yolov3-tiny.onnx')\n",
    "results = run_inference(model, letterbox_img)\n",
    "\n",
    "print(len(results))      # a list of 2 np.arrays\n",
    "print(results[0].shape)  # 13x13\n",
    "print(results[1].shape)  # 26x26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b253d4d-21cd-4fdf-a5f1-d772f9139897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + math.exp(-x))\n",
    "\n",
    "def iou():\n",
    "    return None\n",
    "\n",
    "def process_results(res, pobj_threshold = 0.1, pcls_threshold = 0.5, iou_threshold = 0.5,\n",
    "                    orig_img_size = 416,\n",
    "                    anchors = [[[81,82], [135,169], [344,319]],     # mask 0,1,2\n",
    "                               [[10,14], [ 23, 27], [ 37, 58]]]):   # mask 3,4,5\n",
    "                    #anchors = [[[10,14], [ 23, 27], [ 37, 58]],     # mask 0,1,2\n",
    "                    #           [[81,82], [135,169], [344,319]]]):   # mask 3,4,5\n",
    "    detections = []\n",
    "\n",
    "    for blk in range(len(results)):\n",
    "        stride = orig_img_size/res[blk].shape[1]  # ASSUMES square image\n",
    "        #print(\"YOLO block\", blk, \", stride =\", stride)\n",
    "        det = np.reshape(res[blk], (res[blk].shape[1], res[blk].shape[2], 3, 85))\n",
    "        #print(\"************************\", res[blk].shape, \"-->\", det.shape ,\"*************************\")\n",
    "        for hi in range(res[blk].shape[1]):\n",
    "            for wi in range(res[blk].shape[2]):\n",
    "                for anchor_idx in range(3):\n",
    "                    detection = det[hi][wi][anchor_idx]\n",
    "                    pobj = sigmoid(detection[4])\n",
    "                    \n",
    "                    if pobj > pobj_threshold:\n",
    "                        #print(hi, wi, anchor_idx, \"Anchor:\", anchors[blk][anchor_idx], \"p(obj):\", pobj)\n",
    "                        # Compute the bounding box\n",
    "                        x = stride*(wi + sigmoid(detection[0]))\n",
    "                        y = stride*(hi + sigmoid(detection[1]))\n",
    "                        w = math.exp(detection[2])*anchors[blk][anchor_idx][0]\n",
    "                        h = math.exp(detection[3])*anchors[blk][anchor_idx][1]\n",
    "                        #print(\"   p(obj) =\", pobj,\n",
    "                        #      \"| bbox(x, y, w, h) =\", [x, y, w, h])\n",
    "                        \n",
    "                        # Find possible classes\n",
    "                        for ci in range(80):\n",
    "                            pclass = sigmoid(detection[5+ci])\n",
    "                            if pclass > pcls_threshold:\n",
    "                                #print(\"      p(class) =\", pclass, \"| class =\", classes[ci])\n",
    "                                detections.append((pobj, pclass, ci, x-w/2., y-h/2., x+w/2., y+h/2.))\n",
    "    return detections\n",
    "\n",
    "def print_detections(detections):\n",
    "    for det in detections:\n",
    "        print(\"p(obj)=%.4f, (x,y)_lo=(%3d, %3d), (x,y)_hi=(%3d x %3d), pclass=%.4f, %s\" %\n",
    "              (det[0], det[3], det[4], det[5], det[6], det[1], classes[det[2]]))\n",
    "\n",
    "# detections : pobj, pclass, ci, xl, yl, xh, yh\n",
    "detections = process_results(results, pobj_threshold=0.2)\n",
    "detections.sort()\n",
    "print_detections(detections)\n",
    "\n",
    "annos = []\n",
    "for det in detections:\n",
    "    annos.append(([det[3], det[4],\n",
    "                   det[5], det[6]],\n",
    "                  det[0]*det[1],\n",
    "                  det[2]))\n",
    "\n",
    "tmp_img = np.copy(letterbox_img)\n",
    "anno_img = draw_annos(tmp_img, annos, classes)\n",
    "plt.imshow(anno_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b4ff1-b200-4eeb-9b32-586f6e4a97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(lo1, hi1, lo2, hi2):\n",
    "    lo = max(lo1, lo2)\n",
    "    hi = min(hi1, hi2)\n",
    "    return hi - lo\n",
    "\n",
    "\n",
    "def iou(bbox1, bbox2):  # bbox : [xl, yl, xh, yh]\n",
    "    area1 = (bbox1[2] - bbox1[0])*(bbox1[3] - bbox1[1])\n",
    "    area2 = (bbox2[2] - bbox2[0])*(bbox2[3] - bbox2[1])\n",
    "\n",
    "    #intersection\n",
    "    wo = overlap(bbox1[0], bbox1[2], bbox2[0], bbox2[2])\n",
    "    ho = overlap(bbox1[1], bbox1[3], bbox2[1], bbox2[3])\n",
    "    i_area = 0.\n",
    "    if wo > 0. and ho > 0.:\n",
    "        i_area = wo*ho\n",
    "\n",
    "    #union\n",
    "    u_area = area1 + area2 - i_area\n",
    "\n",
    "    return i_area / u_area\n",
    "\n",
    "\n",
    "# REMEMBER: detections : (pobj, pclass, ci, xl, yl, xh, yh)\n",
    "def basic_nms(dets, iou_threshold = 0.5):\n",
    "    dets.sort(reverse=True);\n",
    "    print(\"Original detections (sorted hi->lo):\")\n",
    "    print_detections(dets)\n",
    "\n",
    "    filtered_detections = []\n",
    "    while len(dets) > 0:\n",
    "        curr_det = dets[0]\n",
    "        filtered_detections.append(curr_det)\n",
    "        print(\"** Keeping and comparing to:\")\n",
    "        print_detections([curr_det])\n",
    "\n",
    "        dets = [d for d in dets if not (curr_det[2] == d[2] and iou(curr_det, d) > iou_threshold)]\n",
    "        print(\"remaining dets:\")\n",
    "        print_detections(dets)\n",
    "        \n",
    "    print(\"Filtered detections:\")\n",
    "    print_detections(filtered_detections)\n",
    "    return filtered_detections\n",
    "\n",
    "filtered_dets = basic_nms(detections)\n",
    "\n",
    "filtered_annos = []\n",
    "for det in filtered_dets:\n",
    "    filtered_annos.append(([det[3], det[4],\n",
    "                             det[5], det[6]],\n",
    "                             det[0]*det[1],\n",
    "                             det[2]))\n",
    "\n",
    "tmp1_img = np.copy(letterbox_img)\n",
    "anno_img = draw_annos(tmp1_img, filtered_annos, classes)\n",
    "plt.imshow(anno_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
