{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cd24b-ecb8-4d8f-9d22-1060cf6dda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26754016-eded-44ca-a9ff-a656afe02aae",
   "metadata": {},
   "source": [
    "* Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b61a8-3a72-48af-91c1-54e66ac26f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letterbox procedure\n",
    "def letterbox(src, dest_shape):\n",
    "    # get src dims\n",
    "    src_width = src.shape[1]    # img.shape returns tuple (rows, cols, chan)\n",
    "    src_height = src.shape[0]   # NOTE: rows => height; cols => width\n",
    "\n",
    "    # cons dest array (filled with gray), get dest dims\n",
    "    # NOTE: each 32-bit [R, G, B] pixel value is [128, 128, 128]\n",
    "    dest = np.full(dest_shape, np.uint8(128))\n",
    "    dest_width = dest.shape[1]\n",
    "    dest_height = dest.shape[0]\n",
    "\n",
    "    # calculate width and height ratios\n",
    "    width_ratio = dest_width / src_width        # NOTE: ratios are float values\n",
    "    height_ratio = dest_height / src_height\n",
    "\n",
    "    # init resized image width and height with max values (dest dims)\n",
    "    rsz_width = dest_width\n",
    "    rsz_height = dest_height\n",
    "\n",
    "    # smallest scale factor will scale other dimension as well\n",
    "    if width_ratio < height_ratio:\n",
    "        rsz_height = int(src_height * width_ratio)  # NOTE: integer truncation\n",
    "    else:\n",
    "        rsz_width = int(src_width * height_ratio)\n",
    "\n",
    "    # resize the image data using bi-linear interpolation\n",
    "    rsz_dims = (rsz_width, rsz_height)\n",
    "    rsz = cv2.resize(src, rsz_dims, 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "    # embed rsz into the center of dest\n",
    "    dx = int((dest_width - rsz_width) / 2)          # NOTE: integer truncation\n",
    "    dy = int((dest_height - rsz_height) / 2)\n",
    "    dest[dy:dy+rsz_height, dx:dx+rsz_width, :] = rsz\n",
    "\n",
    "    # letterboxing complete, return dest\n",
    "    return dest\n",
    "\n",
    "# pack_buffer procedure, ONNX model expects normalized float32 NCHW tensor\n",
    "def pack_buffer(src):\n",
    "    dest = np.array(src, dtype='float32')       # cons dest array via copy\n",
    "    dest /= 255.0                               # normalize vals\n",
    "    dest = np.transpose(dest, [2, 0, 1])        # make channel first dim\n",
    "    dest = np.expand_dims(dest, 0)              # ins batch dim before chan dim\n",
    "    return dest\n",
    "\n",
    "# proc_results procedure\n",
    "def proc_results(res):\n",
    "    [boxes, scores, indices] = res\n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    for idx in indices[0]:\n",
    "        out_classes.append(idx[1])\n",
    "        out_scores.append(scores[tuple(idx)])\n",
    "        idx1 = (idx[0], idx[2])\n",
    "        out_boxes.append(boxes[idx1])\n",
    "    return (out_boxes, out_scores, out_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097fb33-11ce-402b-836a-023d8442edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display test image\n",
    "\n",
    "# open test image\n",
    "arr1 = cv2.imread('../data/dog.jpg')  # default: bgr for display\n",
    "plt.imshow(arr1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2e529-c8c6-4f68-8b32-87c441499b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use openCV to reverse channel order\n",
    "plt.imshow(cv2.cvtColor(arr1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072d360-0295-4149-a1a7-51aa50570dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert channels a different way\n",
    "\n",
    "arr2 = arr1[..., ::-1]                  # bgr -> rgb for inference\n",
    "plt.imshow(arr2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be45f29-7efa-44cc-9cb2-0b815dcbddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letterbox the image to resize for NN input (size: (height, width, chan))\n",
    "arr3 = letterbox(arr2, (416, 416, 3))\n",
    "plt.imshow(arr3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae440c8-4c31-456d-bac7-9619dbd31297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the model classes\n",
    "classes_path = '../model/coco.names'\n",
    "file = open(classes_path, 'r')\n",
    "classes = []\n",
    "while True:\n",
    "    class_name = file.readline().strip()\n",
    "    if not class_name:\n",
    "        break\n",
    "    classes.append(class_name)\n",
    "file.close()\n",
    "#print(\"Classes:\",classes)\n",
    "\n",
    "# cons ONNX Tiny YOLOv3 NN model\n",
    "onnx_model_path = '../model/yolov3-tiny.onnx'\n",
    "infer_sess = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# cons input for ONNX model inference (packed images and their orig dims)\n",
    "arr4 = pack_buffer(arr3)\n",
    "dim4 = np.array([arr1.shape[1], arr1.shape[0]], dtype=np.float32).reshape(1, 2)\n",
    "\n",
    "# run ONNX model inference on input buffer to get results\n",
    "res = infer_sess.run(None, {'input_1': arr4, 'image_shape': dim4})\n",
    "\n",
    "# process results to make list of annotations\n",
    "annos = proc_results(res)\n",
    "print(f'>>> boxes\\n{annos[0]}')\n",
    "print(f'>>> scores\\n{annos[1]}')\n",
    "print(f'>>> classes\\n{annos[2]}')\n",
    "for cls in annos[2]:\n",
    "    print(\"Class id: %d (%s)\" % (cls, classes[cls])) \n",
    "\n",
    "# draw list of annotations on letterboxed image\n",
    "# arr5 = draw_annotations(annos, arr1)\n",
    "\n",
    "# show annotated image\n",
    "# cv2.imshow(wnd_name, arr5)\n",
    "# cv2.imshow(wnd_name, arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b4ff1-b200-4eeb-9b32-586f6e4a97ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
